<!DOCTYPE html>
<html lang="zh-Hans">
<head>

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content=" liusha" />


    
    


<meta name="description" content="人工智能、机器学习、深度学习、数据挖掘、深度聚类">
<meta property="og:type" content="website">
<meta property="og:title" content="流沙">
<meta property="og:url" content="https://jpccc.github.io/index.html">
<meta property="og:site_name" content="流沙">
<meta property="og:description" content="人工智能、机器学习、深度学习、数据挖掘、深度聚类">
<meta property="og:locale">
<meta property="article:author" content=" liusha">
<meta property="article:tag" content="人工智能、机器学习、深度学习、数据挖掘、深度聚类">
<meta name="twitter:card" content="summary">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="流沙" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">



<link rel="stylesheet" href="/css/style.css">



    <style> .article { opacity: 0;} </style>


<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>流沙</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: true,
        isPost: false,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.0"></head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/"></a></h1>
        </hgroup>

        

        
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="" />
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class='no-result'>No results found <i class='fa fa-spinner fa-pulse'></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        
                        <li>友情链接</li>
                        
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="https://jpccc.github.io/">主页</a></li>
                        
                            <li><a href="/archives/">所有文章</a></li>
                        
                            <li><a href="/tags/%E9%9A%8F%E7%AC%94">随笔</a></li>
                        
                            <li><a href="/tags/">标签云</a></li>
                        
                            <li><a href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:jiangpc21@mails.glu.edu.cn" title="Email"></a>
                            
                                <a class="fa GitHub" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" href="/atom.xml" title="RSS"></a>
                            
                                <a class="fa QQ" href="/1778013127" title="QQ"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/deepLearning/" rel="tag">deepLearning</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/math/" rel="tag">math</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/pytorch/" rel="tag">pytorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/" rel="tag">统计学习</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://hexo.io">Hexo</a>
                    
                      <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="https://pages.github.com/">GitHub</a>
                    
                      <a class="main-nav-link switch-friends-link" target="_blank" rel="noopener" href="http://moxfive.xyz/">MOxFIVE</a>
                    
                    </div>
                </section>
                

                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">机器学习</div>
                </section>
                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页"></a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页"></a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="https://jpccc.github.io/">主页</a></li>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/tags/%E9%9A%8F%E7%AC%94">随笔</a></li>
                
                    <li><a href="/tags/">标签云</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:jiangpc21@mails.glu.edu.cn" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="#" title="GitHub"></a>
                            
                                <a class="fa RSS" target="_blank" href="/atom.xml" title="RSS"></a>
                            
                                <a class="fa QQ" target="_blank" href="/1778013127" title="QQ"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="标签" friends="友情链接" about="关于我"/>
</nav>
      <div class="body-wrap">
  
    <article id="post-pytorch使用" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/04/07/pytorch%E4%BD%BF%E7%94%A8/" class="article-date">
      <time datetime="2022-04-07T04:44:13.000Z" itemprop="datePublished">2022-04-07</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/04/07/pytorch%E4%BD%BF%E7%94%A8/">pytorch使用</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              <h2 id="模型的保存和读取"><a href="#模型的保存和读取" class="headerlink" title="模型的保存和读取"></a>模型的保存和读取</h2><p>​    </p>
<table>
<thead>
<tr>
<th>保存</th>
<th align="left">（1）torch.save(net.state_dict(),保存路径) 。（2）多卡训练时，要用 torch.save(net.module.state_dict(),’./model/best.pth’)</th>
</tr>
</thead>
<tbody><tr>
<td>读取</td>
<td align="left">（1）net.load_state_dict(torch.load(‘best.pth’))。（2）并行时map_location=device.type在读取模型的时候一定要加上。即：    model.load_state_dict(torch.load(‘model/self_train_bestv2.pth’,map_location=’cuda’))</td>
</tr>
<tr>
<td></td>
<td align="left"></td>
</tr>
</tbody></table>
          
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pytorch/" rel="tag">pytorch</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2022/04/07/pytorch%E4%BD%BF%E7%94%A8/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-深度学习 tricks" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20tricks/" class="article-date">
      <time datetime="2022-04-06T15:06:13.000Z" itemprop="datePublished">2022-04-06</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/04/06/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%20tricks/">深度学习训练tricks</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h1 id="深度神经网络模型训练中的-tricks（原理与代码汇总）"><a href="#深度神经网络模型训练中的-tricks（原理与代码汇总）" class="headerlink" title="深度神经网络模型训练中的 tricks（原理与代码汇总）"></a>深度神经网络模型训练中的 tricks（原理与代码汇总）</h1><p>本文总结了多种<strong>图像分类</strong>任务中的重要技巧，对于<strong>目标检测和图像分割</strong>等任务，也起到了不错的作用。</p>
<p>计算机视觉主要问题有图像分类、目标检测和图像分割等。针对图像分类任务，提升准确率的方法路线有两条，一个是<em>模型的修改</em>，另一个是*各种数据处理和训练的技巧(tricks)*。图像分类中的各种技巧对于目标检测、图像分割等任务也有很好的作用，因此值得好好总结。本文在精读论文的基础上，总结了图像分类任务的各种tricks如下：</p>
<ul>
<li><p>Warmup</p>
</li>
<li><p>Linear scaling learning rate</p>
</li>
<li><p>Label-smoothing</p>
</li>
<li><p>Random image cropping and patching</p>
</li>
<li><p>Knowledge Distillation</p>
</li>
<li><p>Cutout</p>
</li>
<li><p>Random erasing</p>
</li>
<li><p>Cosine learning rate decay</p>
</li>
<li><p>Mixup training</p>
</li>
<li><p>AdaBoud</p>
</li>
<li><p>AutoAugment</p>
</li>
<li><p>其他经典的tricks</p>
</li>
</ul>
<h2 id="Warmup"><a href="#Warmup" class="headerlink" title="Warmup"></a>Warmup</h2><p>学习率是神经网络训练中最重要的超参数之一，针对学习率的技巧有很多。Warm up是在ResNet论文[1]中提到的一种学习率预热的方法。由于刚开始训练时模型的权重(weights)是随机初始化的(全部置为0是一个坑，原因见[2])，此时选择一个较大的学习率，可能会带来模型的不稳定。学习率预热就是在刚开始训练的时候先使用一个较小的学习率，训练一些epoches或iterations，等模型稳定时再修改为预先设置的学习率进行训练。论文[1]中使用一个110层的ResNet在cifar10上训练时，先用0.01的学习率训练直到训练误差低于80%(大概训练了400个iterations)，然后使用0.1的学习率进行训练。</p>
<p>上述的方法是constant warmup，18年Facebook又针对上面的warmup进行了改进[3]，因为从一个很小的学习率一下变为比较大的学习率可能会导致训练误差突然增大。论文[3]提出了gradual warmup来解决这个问题，即从最开始的小学习率开始，每个iteration增大一点，直到最初设置的比较大的学习率。</p>
<h2 id="Linear-scaling-learning-rate"><a href="#Linear-scaling-learning-rate" class="headerlink" title="Linear scaling learning rate"></a>Linear scaling learning rate</h2><p>Linear scaling learning rate是在论文[3]中针对比较大的batch size而提出的一种方法。</p>
<p>在凸优化问题中，随着批量的增加，收敛速度会降低，神经网络也有类似的实证结果。随着batch size的增大，处理相同数据量的速度会越来越快，但是达到相同精度所需要的epoch数量越来越多。也就是说，使用相同的epoch时，大batch size训练的模型与小batch size训练的模型相比，验证准确率会减小。</p>
<p>上面提到的gradual warmup是解决此问题的方法之一。另外，linear scaling learning rate也是一种有效的方法。在mini-batch SGD训练时，梯度下降的值是随机的，因为每一个batch的数据是随机选择的。增大batch size不会改变梯度的期望，但是会降低它的方差。也就是说，大batch size会降低梯度中的噪声，所以我们可以增大学习率来加快收敛。</p>
<p>具体做法很简单，比如ResNet原论文[1]中，batch size为256时选择的学习率是0.1，当我们把batch size变为一个较大的数b时，学习率应该变为 0.1 × b/256。</p>
<h2 id="Label-smoothing"><a href="#Label-smoothing" class="headerlink" title="Label-smoothing"></a>Label-smoothing</h2><p>在分类问题中，我们的最后一层一般是全连接层，然后对应标签的one-hot编码，即把对应类别的值编码为1，其他为0。这种编码方式和通过降低交叉熵损失来调整参数的方式结合起来，会有一些问题。这种方式会鼓励模型对不同类别的输出分数差异非常大，或者说，模型过分相信它的判断。但是，对于一个由多人标注的数据集，不同人标注的准则可能不同，每个人的标注也可能会有一些错误。<strong>模型对标签的过分相信会导致过拟合。</strong></p>
<p>标签平滑(Label-smoothing regularization,LSR)是应对该问题的有效方法之一，它的具体思想是降低我们对于标签的信任，例如我们可以将损失的目标值从1稍微降到0.9，或者将从0稍微升到0.1。标签平滑最早在inception-v2[4]中被提出，它将真实的概率改造为：</p>
<p><img src="https://jpccc.github.io/resource/deepLearning/640.jpeg" alt="图片"></p>
<p>其中，ε是一个小的常数，K是类别的数目，y是图片的真正的标签，i代表第i个类别，q_i是图片为第i类的概率。</p>
<p>总的来说，LSR是一种通过在标签y中加入噪声，实现对模型约束，降低模型过拟合程度的一种正则化方法。</p>
<p>LSR代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torchimport torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LSR</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, e=<span class="number">0.1</span>, reduction=<span class="string">&#x27;mean&#x27;</span></span>):</span>        </span><br><span class="line">    	<span class="built_in">super</span>().__init__()</span><br><span class="line">        self.log_softmax = nn.LogSoftmax(dim=<span class="number">1</span>)        </span><br><span class="line">        self.e = e        </span><br><span class="line">        self.reduction = reduction</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_one_hot</span>(<span class="params">self, labels, classes, value=<span class="number">1</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;            </span></span><br><span class="line"><span class="string">        Convert labels to one hot vectors</span></span><br><span class="line"><span class="string">        Args:            </span></span><br><span class="line"><span class="string">        labels: torch tensor in format [label1, label2, label3, ...]            </span></span><br><span class="line"><span class="string">        classes: int, number of classes            </span></span><br><span class="line"><span class="string">        value: label value in one hot vector, default to 1</span></span><br><span class="line"><span class="string">        Returns: return one hot format labels in shape [batchsize, classes]        </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        one_hot = torch.zeros(labels.size(<span class="number">0</span>), classes)</span><br><span class="line">        <span class="comment">#labels and value_added  size must match        </span></span><br><span class="line">        labels = labels.view(labels.size(<span class="number">0</span>), -<span class="number">1</span>)        </span><br><span class="line">        value_added = torch.Tensor(labels.size(<span class="number">0</span>), <span class="number">1</span>).fill_(value)</span><br><span class="line">        value_added = value_added.to(labels.device)        </span><br><span class="line">        one_hot = one_hot.to(labels.device)</span><br><span class="line">        one_hot.scatter_add_(<span class="number">1</span>, labels, value_added)</span><br><span class="line">		<span class="keyword">return</span> one_hot</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_smooth_label</span>(<span class="params">self, target, length, smooth_factor</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        convert targets to one-hot format, and smooth them.       </span></span><br><span class="line"><span class="string">        Args:            </span></span><br><span class="line"><span class="string">        target: target in form with [label1, label2, label_batchsize]            </span></span><br><span class="line"><span class="string">        length: length of one-hot format(number of classes)            </span></span><br><span class="line"><span class="string">        smooth_factor: smooth factor for label smooth</span></span><br><span class="line"><span class="string">        Returns:smoothed labels in one hot format        </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span>        </span><br><span class="line">        one_hot = self._one_hot(target, length, value=<span class="number">1</span>- smooth_factor)        </span><br><span class="line">        one_hot += smooth_factor / length</span><br><span class="line">        <span class="keyword">return</span> one_hot.to(target.device)</span><br></pre></td></tr></table></figure>

<h2 id="Random-image-cropping-and-patching"><a href="#Random-image-cropping-and-patching" class="headerlink" title="Random image cropping and patching"></a>Random image cropping and patching</h2><p>Random image cropping and patching (RICAP)[7]方法随机裁剪四个图片中的部分，然后把它们拼接为一个图片，同时混合这四个图片的标签。</p>
<p>RICAP在caifar10上达到了2.19%的错误率。</p>
<p><img src="https://jpccc.github.io/resource/deepLearning/640.jpeg" alt="图片"></p>
<p>如下图所示，Ix, Iy是原始图片的宽和高。w和h称为boundary position，它决定了四个裁剪得到的小图片的尺寸。w和h从beta分布Beta(β, β)中随机生成，β也是RICAP的超参数。最终拼接的图片尺寸和原图片尺寸保持一致。</p>
<p><img src="https://jpccc.github.io/resource/deepLearning/640-16493198579212.jpeg" alt="图片"></p>
<p><img src="https://jpccc.github.io/resource/deepLearning/640-16493198617344.jpeg" alt="图片"></p>
<h2 id="Knowledge-Distillation"><a href="#Knowledge-Distillation" class="headerlink" title="Knowledge Distillation"></a>Knowledge Distillation</h2><p>提高几乎所有机器学习算法性能的一种非常简单的方法是在相同的数据上训练许多不同的模型，然后对它们的预测进行平均。但是使用所有的模型集成进行预测是比较麻烦的，并且可能计算量太大而无法部署到大量用户。Knowledge Distillation(知识蒸馏)[8]方法就是应对这种问题的有效方法之一。</p>
<p>在知识蒸馏方法中，我们使用一个教师模型来帮助当前的模型（学生模型）训练。教师模型是一个较高准确率的预训练模型，因此学生模型可以在保持模型复杂度不变的情况下提升准确率。比如，可以使用ResNet-152作为教师模型来帮助学生模型ResNet-50训练。在训练过程中，我们会加一个蒸馏损失来惩罚学生模型和教师模型的输出之间的差异。</p>
<p>给定输入，假定p是真正的概率分布，z和r分别是学生模型和教师模型最后一个全连接层的输出。之前我们会用交叉熵损失l(p,softmax(z))来度量p和z之间的差异，这里的蒸馏损失同样用交叉熵。所以，使用知识蒸馏方法总的损失函数是</p>
<p><img src="https://jpccc.github.io/resource/deepLearning/640-16493202572062.jpeg" alt="图片"></p>
<p>上式中，第一项还是原来的损失函数，第二项是添加的用来惩罚学生模型和教师模型输出差异的蒸馏损失。其中，T是一个温度超参数，用来使softmax的输出更加平滑的。实验证明，用ResNet-152作为教师模型来训练ResNet-50，可以提高后者的准确率。</p>
<p>##Cutout</p>
<p>Cutout[9]是一种新的正则化方法。原理是在训练时随机把图片的一部分减掉，这样能提高模型的鲁棒性。它的来源是计算机视觉任务中经常遇到的物体遮挡问题。通过cutout生成一些类似被遮挡的物体，不仅可以让模型在遇到遮挡问题时表现更好，还能让模型在做决定时更多地考虑环境(context)。</p>
<p>效果如下图，每个图片的一小部分被cutout了。</p>
<p><img src="https://jpccc.github.io/resource/deepLearning/640-16493198658876.jpeg" alt="图片"></p>
<h2 id="Random-erasing"><a href="#Random-erasing" class="headerlink" title="Random erasing"></a>Random erasing</h2><p>Random erasing[6]其实和cutout非常类似，也是一种模拟物体遮挡情况的数据增强方法。区别在于，cutout是把图片中随机抽中的矩形区域的像素值置为0，相当于裁剪掉，random erasing是用随机数或者数据集中像素的平均值替换原来的像素值。而且，cutout每次裁剪掉的区域大小是固定的，Random erasing替换掉的区域大小是随机的。</p>
<p><img src="https://jpccc.github.io/resource/deepLearning/640-16493198686898.jpeg" alt="图片"></p>
<p><img src="https://jpccc.github.io/resource/deepLearning/640-16493202724694.jpeg" alt="图片"></p>
<h2 id="Cosine-learning-rate-decay"><a href="#Cosine-learning-rate-decay" class="headerlink" title="Cosine learning rate decay"></a>Cosine learning rate decay</h2><p>在warmup之后的训练过程中，学习率不断衰减是一个提高精度的好方法。其中有step decay和cosine decay等，前者是随着epoch增大学习率不断减去一个小的数，后者是让学习率随着训练过程曲线下降。</p>
<p>对于cosine decay，假设总共有T个batch（不考虑warmup阶段），在第t个batch时，学习率η_t为：</p>
<p><img src="https://jpccc.github.io/resource/deepLearning/640-164931987398310.jpeg" alt="图片"></p>
<p>这里，η代表初始设置的学习率。这种学习率递减的方式称之为cosine decay。</p>
<p>下面是带有warmup的学习率衰减的可视化图[4]。其中，图(a)是学习率随epoch增大而下降的图，可以看出cosine decay比step decay更加平滑一点。图(b)是准确率随epoch的变化图，两者最终的准确率没有太大差别，不过cosine decay的学习过程更加平滑。</p>
<p><img src="https://jpccc.github.io/resource/deepLearning/640-164931987712312.jpeg" alt="图片"></p>
<p>在pytorch的torch.optim.lr_scheduler中有更多的学习率衰减的方法，至于哪个效果好，可能对于不同问题答案是不一样的。</p>
<h2 id="Mixup-training"><a href="#Mixup-training" class="headerlink" title="Mixup training"></a>Mixup training</h2><p>Mixup[10]是一种新的数据增强的方法。Mixup training，就是每次取出2张图片，然后将它们线性组合，得到新的图片，以此来作为新的训练样本，进行网络的训练，如下公式，其中x代表图像数据，y代表标签，则得到的新的xhat, yhat。</p>
<p><img src="https://jpccc.github.io/resource/deepLearning/640-16493202939116.jpeg" alt="图片"></p>
<p>其中，λ是从Beta(α, α)随机采样的数，在[0,1]之间。在训练过程中，仅使用(xhat, yhat)。</p>
<p>Mixup方法主要增强了训练样本之间的线性表达，增强网络的泛化能力，不过mixup方法需要较长的时间才能收敛得比较好。</p>
<h2 id="AdaBound"><a href="#AdaBound" class="headerlink" title="AdaBound"></a><strong>AdaBound</strong></h2><p>AdaBound是最近一篇论文[5]中提到的，按照作者的说法，AdaBound会让你的训练过程像adam一样快，并且像SGD一样好。</p>
<p>如下图所示，使用AdaBound会收敛速度更快，过程更平滑，结果更好。</p>
<p><img src="https://jpccc.github.io/resource/deepLearning/640-164931988094314.jpeg" alt="图片"></p>
<p>另外，这种方法相对于SGD对超参数的变化不是那么敏感，也就是说鲁棒性更好。但是，针对不同的问题还是需要调节超参数的，只是所用的时间可能变少了。</p>
<p><img src="https://jpccc.github.io/resource/deepLearning/640-164931988818716.jpeg" alt="图片"></p>
<p>当然，AdaBound还没有经过普遍的检验，也有可能只是对于某些问题效果好。</p>
<p>使用方法如下：安装AdaBound</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install adabound</span><br></pre></td></tr></table></figure>

<p>使用AdaBound(和其他PyTorch optimizers用法一致)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">optimizer = adabound.AdaBound(model.parameters(), lr=1e-3, final_lr=0.1)</span><br></pre></td></tr></table></figure>

<h2 id="AutoAugment"><a href="#AutoAugment" class="headerlink" title="AutoAugment"></a>AutoAugment</h2><p>数据增强在图像分类问题上有很重要的作用，但是增强的方法有很多，并非一股脑地用上所有的方法就是最好的。那么，如何选择最佳的数据增强方法呢？AutoAugment[11]就是一种搜索适合当前问题的数据增强方法的方法。该方法创建一个数据增强策略的搜索空间，利用搜索算法选取适合特定数据集的数据增强策略。此外，从一个数据集中学到的策略能够很好地迁移到其它相似的数据集上。</p>
<p>AutoAugment在cifar10上的表现如下表，达到了98.52%的准确率。</p>
<p><img src="https://jpccc.github.io/resource/deepLearning/640-164931989171518.jpeg" alt="图片"></p>
<h2 id="其他经典的tricks"><a href="#其他经典的tricks" class="headerlink" title="其他经典的tricks"></a>其他经典的tricks</h2><h3 id="常用的正则化方法为"><a href="#常用的正则化方法为" class="headerlink" title="常用的正则化方法为"></a><strong>常用的正则化方法为</strong></h3><ul>
<li>Dropout</li>
<li>L1/L2正则</li>
<li>Batch Normalization</li>
<li>Early stopping</li>
<li>Random cropping</li>
<li>Mirroring</li>
<li>Rotation</li>
<li>Color shifting</li>
<li>PCA color augmentation</li>
<li>…</li>
</ul>
<h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h3><ul>
<li>Xavier init[12]</li>
<li>…</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a><strong>参考资料</strong></h2><p>[1] Deep Residual Learning for Image Recognition(<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1512.03385.pdf">https://arxiv.org/pdf/1512.03385.pdf</a></p>
<p>[2] <a target="_blank" rel="noopener" href="http://cs231n.github.io/neural-networks-2/">http://cs231n.github.io/neural-networks-2/</a></p>
<p>[3] Accurate, Large Minibatch SGD:Training ImageNet in 1 Hour <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1706.02677v2.pdf">https://arxiv.org/pdf/1706.02677v2.pdf</a></p>
<p>[4] <a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/Xnlp7JGx5O_I6ZmjuQ1UGQ">深度神经网络模型训练中的 tricks（原理与代码汇总） (qq.com)</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" rel="tag">深度学习</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-pytorch计算图" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2022/04/06/pytorch%E8%AE%A1%E7%AE%97%E5%9B%BE/" class="article-date">
      <time datetime="2022-04-05T16:08:00.000Z" itemprop="datePublished">2022-04-06</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2022/04/06/pytorch%E8%AE%A1%E7%AE%97%E5%9B%BE/">Understanding Graphs, Automatic Differentiation and Autograd</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              <div align=center>

<p><img src="https://jpccc.github.io/resource/pytorch/full_graph.png" alt="img"></p>
</div>

<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>PyTorch is one of the foremost python deep learning libraries out there. It’s the go to choice for deep learning research, and as each days passes by, more and more companies and research labs are adopting this library.</p>
<p>In this series of tutorials, we will be introducing you to PyTorch, and how to make the best use of the libraries as well the ecosystem of tools built around it. We’ll first cover the basic building blocks, and then move onto how you can quickly prototype custom architectures. We will finally conclude with a couple of posts on how to scale your code, and how to debug your code if things go awry.</p>
<p>This is Part 1 of our PyTorch 101 series.</p>
          
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pytorch/" rel="tag">pytorch</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2022/04/06/pytorch%E8%AE%A1%E7%AE%97%E5%9B%BE/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-Jensen-inequality" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2021/10/28/Jensen-inequality/" class="article-date">
      <time datetime="2021-10-28T08:10:44.000Z" itemprop="datePublished">2021-10-28</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/10/28/Jensen-inequality/">Jensen_inequality</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              <h1 id="Jensen不等式"><a href="#Jensen不等式" class="headerlink" title="Jensen不等式"></a>Jensen不等式</h1><p>Jensen不等式（Jensen’s inequality）是以丹麦数学家Johan Jensen命名的，它在概率论、机器学习、测度论、统计物理等领域都有相关应用。 在机器学习领域，我目前接触到的是用Jensen不等式用来证明KL散度大于等于0。</p>
<blockquote>
<p>Jensen不等式是和凸函数的定义是息息相关的，首先介绍什么是凸函数(convec function)。</p>
</blockquote>
          
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/math/" rel="tag">math</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2021/10/28/Jensen-inequality/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-统计学习part1" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2021/10/28/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0part1/" class="article-date">
      <time datetime="2021-10-28T04:44:13.000Z" itemprop="datePublished">2021-10-28</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/10/28/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0part1/">统计学习数学基础-1</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>对概率的诠释有两大学派，一种是频率派另一种是贝叶斯派。后面我们对观测集采用下面记号：<br>$$<br>X_{N\times p}=(x_{1},x_{2},\cdots,x_{N})^{T},x_{i}=(x_{i1},x_{i2},\cdots,x_{ip})^{T}<br>$$<br>这个记号表示有 $N$ 个样本，每个样本都是 $p$ 维向量。其中每个观测都是由 $p(x|\theta)$ 生成的。</p>
          
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/" rel="tag">统计学习</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2021/10/28/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0part1/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-BN算法" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2021/10/25/BN%E7%AE%97%E6%B3%95/" class="article-date">
      <time datetime="2021-10-25T12:20:14.000Z" itemprop="datePublished">2021-10-25</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/10/25/BN%E7%AE%97%E6%B3%95/">BN算法</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              <h1 id="BN算法概要"><a href="#BN算法概要" class="headerlink" title="BN算法概要"></a>BN算法概要</h1><p>Batch Normalization是2015年一篇论文中提出的数据归一化方法，往往用在深度神经网络中激活层之前。其作用可以加快模型训练时的收敛速度，使得模型训练过程更加稳定，避免梯度爆炸或者梯度消失。并且起到一定的正则化作用，几乎代替了Dropout。</p>
          
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/deepLearning/" rel="tag">deepLearning</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2021/10/25/BN%E7%AE%97%E6%B3%95/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-互信息" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2021/10/25/%E4%BA%92%E4%BF%A1%E6%81%AF/" class="article-date">
      <time datetime="2021-10-25T04:44:13.000Z" itemprop="datePublished">2021-10-25</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/10/25/%E4%BA%92%E4%BF%A1%E6%81%AF/">互信息</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              <h1 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h1><p>机器学习中很多地方都要根据目前的信息做出决策，信息熵主要是反应信息的不确定性；它的一个很重要的作用，就是做决策时提供一定的判断依据，比如决策树根据熵来往下设置分枝(branch)。</p>
<ol>
<li>计算方法 $$H(X)=-\sum_{i=1}^nP(x_i)logP(x_i)$$<br> 其中$P(x_i)$代表随机事件X为$x_i$的概率。</li>
</ol>
          
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/math/" rel="tag">math</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2021/10/25/%E4%BA%92%E4%BF%A1%E6%81%AF/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-algebra" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2021/10/22/algebra/" class="article-date">
      <time datetime="2021-10-22T08:26:34.000Z" itemprop="datePublished">2021-10-22</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/10/22/algebra/">algebra</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
              <h1 id="一-向量"><a href="#一-向量" class="headerlink" title="一. 向量"></a>一. 向量</h1><ol>
<li>向量对于不同的学科有不一样的定义，我们将从三个角度对向量进行解释。<ul>
<li>物理学<br> 物理中的向量由长度和方向决定，长度和方向不变的情况下随意移动，表示的都是同一个向量。</li>
<li>计算机<br> 计算机中的向量更多的是对数据的抽象，可以是根据面积和价格定义的一个房子特征$\begin{bmatrix}100m^2\\700000￥\end{bmatrix}$或是通过神经网络得到的图象的的一个向量。</li>
<li>数学<br> 数学中的向量可以是任意东西，只要保证两个向量的相加$\vec v + \vec w$以及数字和向量相乘$2\vec v$是有意义的即可。
          
      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/math/" rel="tag">math</a></li></ul>
    </div>

      
        <p class="article-more-link">
          <a href="/2021/10/22/algebra/#more">阅读全文 >></a>
        </p>
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
    <article id="post-hello-world" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2021/10/17/hello-world/" class="article-date">
      <time datetime="2021-10-17T07:02:13.391Z" itemprop="datePublished">2021-10-17</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2021/10/17/hello-world/">Hello World</a>
    </h1>
  

      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>Welcome to <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a target="_blank" rel="noopener" href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a target="_blank" rel="noopener" href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a target="_blank" rel="noopener" href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a target="_blank" rel="noopener" href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      

      
      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>









  
  
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2021-2022  liusha
            </div>
            <div class="footer-right">
                回首向来萧瑟处，归去，也无风雨也无晴。
            </div>
        </div>
        
            <div class="visit">
                
                    <span id="busuanzi_container_site_uv">
  本站访客数<span id="busuanzi_value_site_uv"></span>人次
</span>
                
                
                    <span>| </span>
                
                
                    <span id="busuanzi_container_page_pv" style='display:none'>
                        <span id="page-visit"  title="本页阅读量"><i class="fa fa-eye animated infinite pulse" aria-hidden="true"></i><span id="busuanzi_value_page_pv"></span>
                        </span>
                    </span>
                
            </div>
        
    </div>
</footer>
<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>

    <script>
        $(document).ready(function() {
            var iPad = window.navigator.userAgent.indexOf('iPad');
            if (iPad > -1 || $(".left-col").css("display") === "none") {
                var bgColorList = ["#9db3f4", "#414141", "#e5a859", "#f5dfc6", "#c084a0", "#847e72", "#cd8390", "#996731"];
                var bgColor = Math.ceil(Math.random() * (bgColorList.length - 1));
                $("body").css({"background-color": bgColorList[bgColor], "background-size": "cover"});
            }
            else {
                var backgroundnum = 5;
                var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
                $("body").css({"background": backgroundimg, "background-attachment": "fixed", "background-size": "cover"});
            }
        })
    </script>





    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="返回顶部"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="查看评论"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="转到底部"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>